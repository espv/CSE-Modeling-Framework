# This file describes stream processing experiments.

# Each stream processing system must have a program that:
# - parses this yaml file,
# - interprets the necessary commands, and
# - inserts tracepoints to trace metrics such as execution time and throughput (optional).

# The only system specific detail that must be placed in this file is SQL queries.

name: Experiment configuration

experiments:
  - name: experiment 1 --- varying the number of queries
    id: 1
    flow:
      - {command: setIntervalBetweenEvents,         arguments: [0]}
      - {command: setEventBatchSize,                arguments: [1]}
      - {command: addEvents,                        arguments: [4, 1]}
      - {command: addEvents,                        arguments: [2, 1]}
      - {command: addQueries,                       arguments: [1, 1]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [1, 10]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [1, 100]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [1, 1000]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: clearEvents}

  - name: experiment 2 --- varying the number of states in the sequence operator
    id: 2
    flow:
      - {command: setIntervalBetweenEvents,         arguments: [0]}
      - {command: setEventBatchSize,                arguments: [1]}
      - {command: addEvents,                        arguments: [4, 1]}
      - {command: addEvents,                        arguments: [1, 100]}
      - {command: addEvents,                        arguments: [2, 100]}
      - {command: addEvents,                        arguments: [2, 100]}
      - {command: addEvents,                        arguments: [3, 1]}
      - {command: addQueries,                       arguments: [1, 1]}
      - {command: processEvents,                    arguments: [1000]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [2, 1]}
      - {command: processEvents,                    arguments: [1000]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [3, 1]}
      - {command: processEvents,                    arguments: [1000]}
      - {command: clearQueries}
      - {command: clearEvents}

  - name: experiment 3 --- varying the number of unrelated queries
    id: 3
    flow:
      - {command: setIntervalBetweenEvents,         arguments: [0]}
      - {command: setEventBatchSize,                arguments: [1]}
      - {command: addEvents,                        arguments: [4, 1]}
      - {command: addEvents,                        arguments: [2, 1]}
      - {command: addEvents,                        arguments: [4, 1]}
      - {command: addEvents,                        arguments: [2, 1]}
      - {command: addEvents,                        arguments: [4, 1]}
      - {command: addEvents,                        arguments: [2, 1]}
      - {command: addEvents,                        arguments: [4, 1]}
      - {command: addEvents,                        arguments: [1, 100]}
      - {command: addEvents,                        arguments: [2, 1]}
      - {command: addEvents,                        arguments: [3, 1]}
      - {command: addQueries,                       arguments: [4, 1]}
      - {command: processEvents,                    arguments: [1000]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [4, 10]}
      - {command: processEvents,                    arguments: [1000]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [4, 100]}
      - {command: processEvents,                    arguments: [1000]}
      - {command: clearQueries}
      - {command: clearEvents}

  - name: experiment 4 --- varying the number of queries
    id: 4
    flow:
      - {command: setIntervalBetweenEvents,         arguments: [0]}
      - {command: setEventBatchSize,                arguments: [1]}
      - {command: addEvents,                        arguments: [5, 1]}
      - {command: addEvents,                        arguments: [4, 1]}
      - {command: addEvents,                        arguments: [2, 1]}
      - {command: addQueries,                       arguments: [7, 1]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [7, 10]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [7, 100]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [7, 1000]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: clearEvents}

  - name: experiment 5 --- varying the number of queries
    id: 5
    flow:
      - {command: setIntervalBetweenEvents,         arguments: [0]}
      - {command: setEventBatchSize,                arguments: [1]}
      - {command: addDataset,                       arguments: [1]}
      - {command: addQueries,                       arguments: [7, 1]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [7, 10]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [7, 100]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [7, 1000]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: clearEvents}

  - name: experiment 6 --- varying the number of join queries
    id: 6
    flow:
      - {command: setIntervalBetweenEvents,         arguments: [0]}
      - {command: setEventBatchSize,                arguments: [1]}
      - {command: addDataset,                       arguments: [2]}
      - {command: addQueries,                       arguments: [5, 1]}
      - {command: loopCommands,
         arguments: [10, [{command: processEvents,  arguments: [100]},
                          {command: addQueries,     arguments: [5, 1]}]]}
      - {command: clearEvents}

  - name: experiment 7 --- varying the number of two-state then queries
    id: 7
    flow:
      - {command: setIntervalBetweenEvents,         arguments: [0]}
      - {command: setEventBatchSize,                arguments: [1]}
      - {command: addEvents,                        arguments: [4, 1]}
      - {command: addEvents,                        arguments: [4, 1]}
      - {command: addEvents,                        arguments: [4, 1]}
      - {command: addEvents,                        arguments: [1, 1]}
      - {command: addEvents,                        arguments: [1, 1]}
      - {command: addEvents,                        arguments: [1, 1]}
      - {command: addQueries,                       arguments: [9, 1]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [9, 10]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [9, 100]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: addQueries,                       arguments: [9, 1000]}
      - {command: processEvents,                    arguments: [100]}
      - {command: clearQueries}
      - {command: clearEvents}

cepqueries:
  - name: temperature_GT45_and_humidity_LT25_5sec_window
    id: 0
    streams-used-in-query: [10, 11, 12]
    sql-query:
      t-rex: 'Assign 10 => Temp, 11 => Humidity, 12 => Smoke, 1 => Fire
              Define  Fire(area: string, temp: float)
              From   Humidity(percentage<25) and
              last   Temp(temp_value>45, [string] area=Temp.area)
              within 50000000 from Temp and
              last    Smoke(ppm>100, [string] area=Temp.area)
              within 50000000 from Smoke
              Where   area := Temp.area, temp := Temp.temp_value
              Consuming Smoke, Temp, Humidity; '
      siddhi: 'from every t = temperatureStream [temp_value > 45] and
                         (h = humidityStream [percentage < 25])
               select temp_value, percentage, h.area
               insert into fireStream ; '
      flink: 'SELECT *
              FROM temperatureStream t
              JOIN humidityStream h
              ON h.area = t.area '
      esper: 'select *
              from pattern[t=temperatureStream(temp_value>45) ->
                           h=humidityStream(percentage<25)]; '

  - name: temperature_GT45_join_humidity_LT25_5sec_window
    id: 5
    streams-used-in-query: [10, 11, 12]
    sql-query:
      t-rex: 'Assign 10 => Temp, 11 => Humidity, 12 => Smoke, 1 => Fire
              Define  Fire(area: string, temp: float)
              From   Humidity(percentage<25) and
              last   Temp(temp_value>45, [string] area=Temp.area)
              within 50000000 from Temp and
              last    Smoke(ppm>100, [string] area=Temp.area)
              within 50000000 from Smoke
              Where   area := Temp.area, temp := Temp.temp_value
              Consuming Smoke, Temp, Humidity; '
      siddhi: 'from temperatureStream[temp_value > 45]#window.time(1 min) as temp
               join humidityStream[percentage < 25]#window.time(1 min) as humidity
               on temp.area==humidity.area
               select temp_value, percentage, humidity.area
               insert into fireStream; '
      flink: ' SELECT *
               FROM TripStream ts '
      esper: 'select *
              from pattern[t=temperatureStream ->
                           h=humidityStream]; '

  - name: temperature_GT45_then_humidity_LT25_within_5sec
    id: 6
    streams-used-in-query: [10, 11, 12]
    sql-query:
      t-rex: 'Assign 10 => Temp, 11 => Humidity, 12 => Smoke, 1 => Fire
              Define  Fire(area: string, temp: float)
              From   Humidity(percentage<25) and
              last   Temp(temp_value>45, [string] area=Temp.area)
              within 50000000 from Temp and
              last    Smoke(ppm>100, [string] area=Temp.area)
              within 50000000 from Smoke
              Where   area := Temp.area, temp := Temp.temp_value
              Consuming Smoke, Temp, Humidity;'
      siddhi: ' from every t = temperatureStream [temp_value > 45] ->
                        (h = humidityStream [percentage < 25])
              select temp_value, percentage, h.area
              insert into fireStream ; '
      flink: 'SELECT *
              FROM temperatureStream '
      esper: 'select *
              from weatherStream; '

  - name: temperature_GT45_then_humidity_LT25_within_5sec_then_smoke_GT50_within_5sec
    id: 7
    streams-used-in-query: [10, 11, 12]
    sql-query:
      t-rex: 'Assign 10 => Temp, 11 => Humidity, 12 => Smoke, 1 => Fire
              Define  Fire(area: string, temp: float)
              From   Humidity(percentage<25) and
              last   Temp(temp_value>45, [string] area=Temp.area)
              within 50000000 from Temp and
              last    Smoke(ppm>100, [string] area=Temp.area)
              within 50000000 from Smoke
              Where   area := Temp.area, temp := Temp.temp_value
              Consuming Smoke, Temp, Humidity;'
      siddhi: 'from every (t = temperatureStream [temp_value > 45]) ->
                          (h = humidityStream [percentage < 25]) ->
                          (s = smokeStream [ppm > 100]) within 5 seconds
               select temp_value, percentage, h.area
               insert into fireStream ; '
      flink: 'SELECT *
              FROM temperatureStream '
      esper: 'select *
              from temperatureStream; '

  - name: temperature_AVG_GT45_5sec_window
    id: 8
    streams-used-in-query: [10, 11, 12]
    sql-query:
      t-rex: 'Assign 10 => Temp, 11 => Humidity, 12 => Smoke, 1 => Fire
              Define  Fire(area: string, temp: float)
              From   Humidity(percentage<25) and
              last   Temp(temp_value>45, [string] area=Temp.area)
              within 50000000 from Temp and
              last    Smoke(ppm>100, [string] area=Temp.area)
              within 50000000 from Smoke
              Where   area := Temp.area, temp := Temp.temp_value
              Consuming Smoke, Temp, Humidity;'
      siddhi: 'from temperatureStream[temp_value > 45]#window.time(1 min) as temp
               join humidityStream[percentage < 25]#window.time(1 min) as humidity
               on temp.area==humidity.area
               select temp_value, percentage, humidity.area
               insert into fireStream; '
      flink: 'SELECT *
              FROM temperatureStream '
      esper: 'select *
              from weatherStream; '

  - name: temperature_AVG_GT45_5sec_window
    id: 9
    streams-used-in-query: [10, 11, 12]
    sql-query:
      t-rex: 'Assign 10 => Temp, 11 => Humidity, 12 => Smoke, 1 => Fire
              Define  Fire(area: string, temp: float)
              From   Humidity(percentage<25) and
              last   Temp(temp_value>45, [string] area=Temp.area)
              within 50000000 from Temp and
              last    Smoke(ppm>100, [string] area=Temp.area)
              within 50000000 from Smoke
              Where   area := Temp.area, temp := Temp.temp_value
              Consuming Smoke, Temp, Humidity; '
      siddhi: 'from temperatureStream[temp_value > 45]#window.time(1 min) as temp
               join humidityStream[percentage < 25]#window.time(1 min) as humidity
               on temp.area==humidity.area
               select temp_value, percentage, humidity.area
               insert into fireStream; '
      flink: 'SELECT *
              FROM temperatureStream
              MATCH_RECOGNIZE (
                PARTITION BY area
                ORDER BY proctime
                MEASURES
                FIRST(A.proctime) AS start_tstamp,
                LAST(A.proctime) AS end_tstamp,
                AVG(A.temp_value) AS avgTemp
                ONE ROW PER MATCH
                AFTER MATCH SKIP PAST LAST ROW
                PATTERN (A B C D)
                DEFINE
                  B AS B.temp_value > A.temp_value,
                  C AS C.temp_value > B.temp_value,
                  D AS D.temp_value > C.temp_value
              ) MR '
      esper: 'select *
              from temperatureStream
              match_recognize (
                partition by area
                measures A.temp_value as a_temp, B.temp_value as b_temp
                pattern (A B C D)
                define
                  B as B.temp_value > A.temp_value,
                  C as C.temp_value > B.temp_value,
                  D as D.temp_value > C.temp_value
              ); '

stream-definitions:
  - id: 1
    stream-id: 10
    name: temperatureStream
    tuple-format: [{name: temp_value, type: long}, {name: area, type: string}]
    siddhi: 'define stream temperatureStream (temp_value long, area string);'
    esper: 'create schema temperatureStream as (temp_value long, area String);'

  - id: 2
    stream-id: 11
    name: humidityStream
    tuple-format: [{name: percentage, type: long}, {name: area, type: string}]
    siddhi: 'define stream humidityStream (percentage long, area string);'
    esper: 'create schema humidityStream (percentage long, area String);'

  - id: 3
    stream-id: 1
    name: fireStream
    tuple-format: [{name: temp_value, type: long}, {name: percentage, type: long}, {name: area, type: string}]
    siddhi: 'define stream fireStream (temp_value long, percentage long, area string);'
    esper: 'create schema fireStream (temp_value long, percentage long, area String);'

  - id: 4
    stream-id: 12
    name: smokeStream
    tuple-format: [{name: ppm, type: long}, {name: area, type: string}]
    siddhi: 'define stream smokeStream (ppm float, area string);'
    esper: 'create schema smokeStream (ppm float, area String);'

  - id: 5
    stream-id: 13
    name: weatherStream
    tuple-format: [{name: STATION, type: string}, {name: NAME, type: string}, {name: DATE, type: timestamp},
                   {name: AWND, type: float}, {name: PRCP, type: float}, {name: SNOW, type: float},
                   {name: SNWD, type: float}, {name: TMAX, type: float}, {name: TMIN, type: float}]
    siddhi: 'define stream weatherStream (STATION string, NAME string, DATE string, AWND float, PRCP float,
                                          SNOW float, SNWD float, TMAX float, TMIN float);'
    esper: 'create schema weatherStream (STATION String, NAME String, DATE String, AWND float, PRCP float,
                                         SNOW float, SNWD float, TMAX float, TMIN float);'

  - id: 6
    stream-id: 14
    name: weatherStream2
    tuple-format: [{name: STATION, type: string}, {name: NAME, type: string}, {name: DATE, type: timestamp},
                   {name: AWND, type: float}, {name: PRCP, type: float}, {name: SNOW, type: float},
                   {name: SNWD, type: float}, {name: TMAX, type: float}, {name: TMIN, type: float}]
    siddhi: 'define stream weatherStream2 (STATION string, NAME string, DATE string, AWND float, PRCP float,
                                          SNOW float, SNWD float, TMAX float, TMIN float);'
    esper: 'create schema weatherStream2 (STATION String, NAME String, DATE String, AWND float, PRCP float,
                                         SNOW float, SNWD float, TMAX float, TMIN float);'

  - id: 7
    stream-id: 15
    name: TripStream
    tuple-format: [{name: Dispatching_base_num, type: string}, {name: Pickup_date, type: timestamp},
                   {name: locationID, type: string}]
    siddhi: 'define stream TripStream (Dispatching_base_num string, Pickup_date string, locationID string);'
    esper: 'create schema TripStream (Dispatching_base_num String, Pickup_date String, locationID String);'

datasets:
  - name: Central park weather (CSV)
    type: csv
    id: 1
    stream-id: 13
    file: /home/espen/Research/nyc-taxi-data/data/central_park_weather-cleaned.csv

  - name: Central park weather (YAML)
    type: yaml
    id: 2
    file: /home/espen/Research/nyc-taxi-data/data/central_park_weather-merged.yaml

cepevents:
  - {name: temperature_22degrees, id: 1, stream-id: 10, stream-name: temperatureStream,
     attributes: [{name: temp_value, value: 22}, {name: area, value: office}]}
  - {name: humidity_24percent, id: 2, stream-id: 11, stream-name: humidityStream,
     attributes: [{name: percentage, value: 24}, {name: area, value: office}]}
  - {name: humidity_44percent, id: 3, stream-id: 11, stream-name: humidityStream,
     attributes: [{name: percentage, value: 44}, {name: area, value: office}]}
  - {name: temperature_46degrees, id: 4, stream-id: 10, stream-name: temperatureStream,
     attributes: [{name: temp_value, value: 46}, {name: area, value: office}]}
  - {name: smoke_101_ppm, id: 5, stream-id: 12, stream-name: smokeStream,
     attributes: [{name: ppm, value: 101}, {name: area, value: office}]}
  - {name: smoke_99_ppm, id: 6, stream-id: 12, stream-name: smokeStream,
     attributes: [{name: ppm, value: 99}, {name: area, value: office}]}

tracepoints:
  - id: 1
    name: receiveEvent
    active: true
    arguments:
      - name: tid
        type: int
      - name: CurCepEvent
        type: int
    description:
    category:
      isScalingEvent: false
      isMilestoneEvent: true

  - id: 2
    name:
    active: false
    arguments:
      - name: tid
        type: int
      - name: CurCepEvent
        type: int
    description:
    category:
      isScalingEvent: false
      isMilestoneEvent: false

  - id: 3
    name:
    active: false
    arguments:
      - name: tid
        type: int
      - name: CurCepEvent
        type: int
    description:
    category:
      isScalingEvent: false
      isMilestoneEvent: false

  - id: 4
    name: passedConstraints
    active: false
    arguments:
      - name: tid
        type: int
      - name: CurCepEvent
        type: int
    description: Passed constraints for query
    category:
      isScalingEvent: false
      isMilestoneEvent: false

  - id: 6
    name: createdComplexEvent
    active: false
    arguments:
      - name: tid
        type: int
      - name: CurCepEvent
        type: int
    description: A complex event was created
    category:
      isScalingEvent: false
      isMilestoneEvent: true

  - id: 100
    name: finishedProcessingEvent
    active: true
    arguments:
      - name: tid
        type: int
      - name: CurCepEvent
        type: int
    description:
    category:
      isScalingEvent: false
      isMilestoneEvent: true

  - id: 221
    name: addQuery
    active: true
    arguments:
      - name: CepQuery
        type: int
    x_variable: numberQueries
    description: Traced when deploying a query. This is a simulation and scaling event.
    category:
      isScalingEvent: true
      isMilestoneEvent: false

  - id: 222
    name: clearQueries
    active: true
    arguments: []
    x_variable: numberQueries
    description: Traced when removing all deployed queries. This is a simulation and scaling event.
    category:
      isScalingEvent: true
      isMilestoneEvent: false

  - id: 220
    name: addEvent
    active: true
    arguments:
      - name: tid
        type: int
      - name: CepEvent
        type: int
    x_variable: numberEvents
    description: Traced when adding an event to the allPackets queue.
    category:
      isScalingEvent: false
      isMilestoneEvent: false

  - id: 223
    name: clearEvents
    active: true
    arguments: []
    x_variable: numberEvents
    description: Traced when clearing all CEP events from allPackets. This is a scaling event.
    category:
      isScalingEvent: true
      isMilestoneEvent: false

  - id: 0
    name: runExperiment
    active: true
    arguments:
      - name: experimentId
        type: int
    x_variable:
    description: Decides which experiment to run
    category:
      isScalingEvent: false
      isMilestoneEvent: false
